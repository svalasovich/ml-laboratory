{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Лабораторная работа №2.\n",
    "## Реализация глубокой нейронной сети"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "import tensorflow as tf"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# 1. Реализуйте полносвязную нейронную сеть с помощью библиотеки Tensor Flow.\n",
    "\n",
    "required_train_size=200000\n",
    "required_test_size=10000\n",
    "labels={}\n",
    "\n",
    "def loadImages(path):\n",
    "    data = {}\n",
    "    index = 0\n",
    "    label_dirs = os.listdir(f\"{path}/\")\n",
    "    for label in label_dirs:\n",
    "        zeros = np.zeros((len(label_dirs)), dtype=np.byte)\n",
    "        zeros[index] = 1\n",
    "        labels[label] = zeros\n",
    "        index += 1\n",
    "        for image in os.listdir(f\"{path}/{label}/\"):\n",
    "            try:\n",
    "                if label not in data:\n",
    "                    data[label] = []\n",
    "                data[label].append(mpimg.imread(f\"{path}/{label}/{image}\").flatten())\n",
    "            except:\n",
    "                pass\n",
    "    return data\n",
    "\n",
    "data_large = loadImages(\"large\")\n",
    "data_small = loadImages(\"small\")\n",
    "\n",
    "def prepareDataset(data):\n",
    "    X = []\n",
    "    y = []\n",
    "    for k, v in data.items():\n",
    "        X = X + v\n",
    "        y = y + [labels[k]]*len(v)\n",
    "    return np.array(X, dtype=np.float32), np.array(y, dtype=np.int32)\n",
    "\n",
    "X, y = prepareDataset(data_large)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=required_test_size, train_size=required_train_size)\n",
    "\n",
    "del X\n",
    "del y\n",
    "del data_large\n",
    "\n",
    "X_test, y_test = prepareDataset(data_small)\n",
    "del data_small"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [],
   "source": [
    "start_learning_rate=0.5\n",
    "shape = X_train.shape[1]\n",
    "num_labels = len(labels.items())\n",
    "optimizer = tf.optimizers.SGD(start_learning_rate)\n",
    "\n",
    "tf_valid_dataset = tf.constant(X_valid)\n",
    "tf_test_dataset = tf.constant(X_test)\n",
    "\n",
    "batch_size = 128\n",
    "dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "dataset = dataset.repeat().shuffle(X_train.shape[0]).batch(batch_size)\n",
    "\n",
    "#Определяет кол-во нейронов и число слоев\n",
    "def prepare_neurons(input_number, output_number, *args):\n",
    "    weights = []\n",
    "    biases = []\n",
    "    previous_number=input_number\n",
    "    seed = [42, 21]\n",
    "\n",
    "    for index, neuron_number in enumerate(args):\n",
    "        weights.append(tf.Variable(tf.random.stateless_normal([previous_number, args[index]], seed), name=f\"weight_{index}\"))\n",
    "        biases.append(tf.Variable(tf.zeros([args[index]]), name=f\"bias_{index}\"))\n",
    "        previous_number=neuron_number\n",
    "\n",
    "    weights.append(tf.Variable(tf.random.stateless_normal([previous_number, output_number], seed), name=\"weight_output\"))\n",
    "    biases.append(tf.Variable(tf.zeros([output_number]), name=\"bias_output\"))\n",
    "\n",
    "    return weights, biases\n",
    "\n",
    "neuron_number_1 = 1024\n",
    "weights, biases = prepare_neurons(shape, num_labels, neuron_number_1)\n",
    "\n",
    "# Определяем функци активации и стоимости\n",
    "layers = [tf.nn.relu]\n",
    "def calculate_prediction(tf_dataset, weigths, biases, layers):\n",
    "    prev_layer = tf_dataset\n",
    "    for index, layer in enumerate(layers):\n",
    "        prev_layer = layer(tf.add(tf.matmul(prev_layer, weigths[index]), biases[index]), name=f\"layer_{index}\")\n",
    "    return tf.matmul(prev_layer, weigths[-1]) + biases[-1]\n",
    "\n",
    "@tf.function\n",
    "def run_optimization(tf_train_dataset, tf_train_labels, optimizer, weights, biases):\n",
    "    def cost():\n",
    "        return tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=calculate_prediction(tf_train_dataset, weights, biases, layers), labels=tf_train_labels))\n",
    "    optimizer.minimize(cost, weights + biases, tape=tf.GradientTape())\n",
    "\n",
    "def train_model(num_steps, weights, biases, optimizer, optimization_function, calculate_prediction_function, tf_last_activation_function=tf.nn.softmax):\n",
    "    for step, (batch_x, batch_y) in enumerate(dataset.take(num_steps), 1):\n",
    "        optimization_function(batch_x, batch_y, optimizer, weights, biases)\n",
    "        if step % 500 == 0 or step < 10:\n",
    "            prediction = tf_last_activation_function(calculate_prediction_function(tf_valid_dataset, weights, biases, layers))\n",
    "            print(\"Validation accuracy:\", metrics.accuracy_score(np.argmax(y_valid, 1), np.argmax(prediction, 1)), \"on step:\", step)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.1275 on step: 1\n",
      "Validation accuracy: 0.2614 on step: 2\n",
      "Validation accuracy: 0.1919 on step: 3\n",
      "Validation accuracy: 0.3295 on step: 4\n",
      "Validation accuracy: 0.2435 on step: 5\n",
      "Validation accuracy: 0.3171 on step: 6\n",
      "Validation accuracy: 0.4895 on step: 7\n",
      "Validation accuracy: 0.5365 on step: 8\n",
      "Validation accuracy: 0.5313 on step: 9\n",
      "Validation accuracy: 0.7045 on step: 500\n",
      "Validation accuracy: 0.7538 on step: 1000\n",
      "Validation accuracy: 0.7746 on step: 1500\n",
      "Validation accuracy: 0.7797 on step: 2000\n",
      "Validation accuracy: 0.7813 on step: 2500\n",
      "Validation accuracy: 0.7918 on step: 3000\n",
      "Validation accuracy: 0.7903 on step: 3500\n",
      "Validation accuracy: 0.802 on step: 4000\n",
      "Validation accuracy: 0.7944 on step: 4500\n",
      "Validation accuracy: 0.7994 on step: 5000\n",
      "Validation accuracy: 0.7642 on step: 5500\n",
      "Validation accuracy: 0.8045 on step: 6000\n"
     ]
    }
   ],
   "source": [
    "num_steps = 6000\n",
    "train_model(num_steps, weights, biases, optimizer, run_optimization, calculate_prediction)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8356 < 0.8748664815210425\n"
     ]
    }
   ],
   "source": [
    "#2. Как улучшилась точность классификатора по сравнению с логистической регрессией?\n",
    "\n",
    "regression_accuracy = 0.8356\n",
    "prediction = tf.nn.softmax(calculate_prediction(tf_test_dataset, weights, biases, layers))\n",
    "deep_learning_accuracy = metrics.accuracy_score(np.argmax(y_test, 1), np.argmax(prediction, 1))\n",
    "\n",
    "print(f\"{regression_accuracy} < {deep_learning_accuracy}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [],
   "source": [
    "#3. Используйте регуляризацию и метод сброса нейронов (dropout) для борьбы с переобучением. Как улучшилось качество классификации?\n",
    "\n",
    "optimizer = tf.optimizers.SGD(start_learning_rate)\n",
    "rate = 0.25\n",
    "weights, biases = prepare_neurons(shape, num_labels, neuron_number_1)\n",
    "layers = [tf.nn.relu]\n",
    "beta = 0.001\n",
    "\n",
    "def calculate_prediction_dropout(tf_dataset, weigths, biases, layers):\n",
    "    prev_dropout = tf_dataset\n",
    "    for index, layer in enumerate(layers):\n",
    "        layer = layer(tf.add(tf.matmul(prev_dropout, weigths[index]), biases[index]), name=f\"layer_{index}\")\n",
    "        prev_dropout = tf.nn.dropout(layer, rate)\n",
    "    return tf.matmul(prev_dropout, weigths[-1]) + biases[-1]\n",
    "\n",
    "def run_optimization_dropout_and_regularization(tf_train_dataset, tf_train_labels, optimizer, weights, biases):\n",
    "    def cost():\n",
    "        regularization = tf.nn.l2_loss(weights[0])\n",
    "        for weight in weights[1:]:\n",
    "            regularization += tf.nn.l2_loss(weight)\n",
    "        loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=calculate_prediction_dropout(tf_train_dataset, weights, biases, layers), labels=tf_train_labels))\n",
    "        return tf.reduce_mean(loss + beta * regularization)\n",
    "    optimizer.minimize(cost, weights + biases, tape=tf.GradientTape())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.1472 on step: 1\n",
      "Validation accuracy: 0.2178 on step: 2\n",
      "Validation accuracy: 0.1826 on step: 3\n",
      "Validation accuracy: 0.2001 on step: 4\n",
      "Validation accuracy: 0.2592 on step: 5\n",
      "Validation accuracy: 0.393 on step: 6\n",
      "Validation accuracy: 0.4634 on step: 7\n",
      "Validation accuracy: 0.4815 on step: 8\n",
      "Validation accuracy: 0.4915 on step: 9\n",
      "Validation accuracy: 0.6335 on step: 500\n",
      "Validation accuracy: 0.7268 on step: 1000\n",
      "Validation accuracy: 0.7476 on step: 1500\n",
      "Validation accuracy: 0.7904 on step: 2000\n",
      "Validation accuracy: 0.8022 on step: 2500\n",
      "Validation accuracy: 0.8145 on step: 3000\n",
      "Validation accuracy: 0.8211 on step: 3500\n",
      "Validation accuracy: 0.8297 on step: 4000\n",
      "Validation accuracy: 0.8434 on step: 4500\n",
      "Validation accuracy: 0.8443 on step: 5000\n",
      "Validation accuracy: 0.8542 on step: 5500\n",
      "Validation accuracy: 0.854 on step: 6000\n",
      "With droput and regularization: 0.924481948301645\n"
     ]
    }
   ],
   "source": [
    "train_model(num_steps, weights, biases, optimizer, run_optimization_dropout_and_regularization, calculate_prediction_dropout)\n",
    "\n",
    "prediction = tf.nn.softmax(calculate_prediction(tf_test_dataset, weights, biases, layers))\n",
    "deep_learning_accuracy_corrected = metrics.accuracy_score(np.argmax(y_test, 1), np.argmax(prediction, 1))\n",
    "\n",
    "print(f\"With droput and regularization: {deep_learning_accuracy_corrected}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.1618 on step: 1\n",
      "Validation accuracy: 0.1737 on step: 2\n",
      "Validation accuracy: 0.1962 on step: 3\n",
      "Validation accuracy: 0.3366 on step: 4\n",
      "Validation accuracy: 0.1649 on step: 5\n",
      "Validation accuracy: 0.3661 on step: 6\n",
      "Validation accuracy: 0.451 on step: 7\n",
      "Validation accuracy: 0.5182 on step: 8\n",
      "Validation accuracy: 0.5119 on step: 9\n",
      "Validation accuracy: 0.6315 on step: 500\n",
      "Validation accuracy: 0.7168 on step: 1000\n",
      "Validation accuracy: 0.7588 on step: 1500\n",
      "Validation accuracy: 0.7878 on step: 2000\n",
      "Validation accuracy: 0.7967 on step: 2500\n",
      "Validation accuracy: 0.8171 on step: 3000\n",
      "Validation accuracy: 0.8261 on step: 3500\n",
      "Validation accuracy: 0.837 on step: 4000\n",
      "Validation accuracy: 0.8428 on step: 4500\n",
      "Validation accuracy: 0.8496 on step: 5000\n",
      "Validation accuracy: 0.8476 on step: 5500\n",
      "Validation accuracy: 0.8514 on step: 6000\n",
      "Validation accuracy: 0.8533 on step: 6500\n",
      "Validation accuracy: 0.8624 on step: 7000\n",
      "Validation accuracy: 0.86 on step: 7500\n",
      "Validation accuracy: 0.8635 on step: 8000\n",
      "With dynamic learning rate: 0.9307306131168553\n"
     ]
    }
   ],
   "source": [
    "# Воспользуйтесь динамически изменяемой скоростью обучения (learning rate). Наилучшая точность, достигнутая с помощью данной модели составляет 97.1%. Какую точность демонстрирует Ваша реализованная модель?\n",
    "\n",
    "num_steps = 8000\n",
    "weights, biases = prepare_neurons(shape, num_labels, neuron_number_1)\n",
    "layers = [tf.nn.relu]\n",
    "learning_rate = tf.keras.optimizers.schedules.ExponentialDecay(start_learning_rate, 4000, 0.9, staircase=True)\n",
    "optimizer = tf.optimizers.SGD(learning_rate)\n",
    "\n",
    "train_model(num_steps, weights, biases, optimizer, run_optimization_dropout_and_regularization, calculate_prediction_dropout)\n",
    "\n",
    "prediction = tf.nn.softmax(calculate_prediction(tf_test_dataset, weights, biases, layers))\n",
    "deep_learning_accuracy_dynamic_learning_rate = metrics.accuracy_score(np.argmax(y_test, 1), np.argmax(prediction, 1))\n",
    "\n",
    "print(f\"With dynamic learning rate: {deep_learning_accuracy_dynamic_learning_rate}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}