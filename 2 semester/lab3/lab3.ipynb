{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Лабораторная работа №3.\n",
    "## Реализация сверточной нейронной сети\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "import tensorflow as tf\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "#1. Реализуйте нейронную сеть с двумя сверточными слоями, и одним полносвязным с нейронами с кусочно-линейной функцией активации. Какова точность построенное модели?\n",
    "\n",
    "\n",
    "required_train_size=200000\n",
    "required_test_size=10000\n",
    "labels={}\n",
    "\n",
    "def loadImages(path):\n",
    "    data = {}\n",
    "    index = 0\n",
    "    label_dirs = os.listdir(f\"{path}/\")\n",
    "    for label in label_dirs:\n",
    "        zeros = np.zeros((len(label_dirs)), dtype=np.byte)\n",
    "        zeros[index] = 1\n",
    "        labels[label] = zeros\n",
    "        index += 1\n",
    "        for image in os.listdir(f\"{path}/{label}/\"):\n",
    "            try:\n",
    "                if label not in data:\n",
    "                    data[label] = []\n",
    "                img = mpimg.imread(f\"{path}/{label}/{image}\")\n",
    "                data[label].append(img.reshape(img.shape[0], img.shape[1], 1))\n",
    "            except:\n",
    "                pass\n",
    "    return data\n",
    "\n",
    "data_large = loadImages(\"large\")\n",
    "data_small = loadImages(\"small\")\n",
    "\n",
    "def prepareDataset(data):\n",
    "    X = []\n",
    "    y = []\n",
    "    for k, v in data.items():\n",
    "        X = X + v\n",
    "        y = y + [labels[k]]*len(v)\n",
    "    return np.array(X, dtype=np.float32), np.array(y, dtype=np.int32)\n",
    "\n",
    "X, y = prepareDataset(data_large)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=required_test_size, train_size=required_train_size)\n",
    "\n",
    "del X\n",
    "del y\n",
    "del data_large\n",
    "\n",
    "X_test, y_test = prepareDataset(data_small)\n",
    "del data_small\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "start_learning_rate=0.05\n",
    "shape = X_train.shape[1]\n",
    "batch_size = 16\n",
    "num_labels = len(labels.items())\n",
    "optimizer = tf.optimizers.SGD(start_learning_rate)\n",
    "\n",
    "#Параметры сверточного слоя\n",
    "padding = 1\n",
    "filter = 5\n",
    "stride = 2\n",
    "deph = 16\n",
    "neurons = 64\n",
    "layers = [tf.nn.relu, tf.nn.relu, tf.nn.relu]\n",
    "\n",
    "def get_final_size(input_size, padding, stride, filters):\n",
    "    output = input_size\n",
    "    for filter in filters:\n",
    "        output = (output + 2 * padding - filter) / stride + 1\n",
    "    return int(np.ceil(output))\n",
    "\n",
    "# Подготовка dataset для обучения\n",
    "tf_valid_dataset = tf.constant(X_valid)\n",
    "tf_test_dataset = tf.constant(X_test)\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "dataset = dataset.repeat().shuffle(X_train.shape[0]).batch(batch_size)\n",
    "\n",
    "#Определяет веса и смещения для слоев\n",
    "def prepare_weights_biases(input_number, output_number, neuron_number, padding, stride, *args):\n",
    "    weights = []\n",
    "    biases = []\n",
    "    previous_deph = 1\n",
    "    stddev=0.1\n",
    "\n",
    "    for deph, filter in args:\n",
    "        weights.append(tf.Variable(tf.random.truncated_normal([filter, filter, previous_deph, deph], stddev=stddev)))\n",
    "        biases.append(tf.Variable(tf.zeros([deph])))\n",
    "        previous_deph = deph\n",
    "\n",
    "    final_image_size = get_final_size(input_number, padding, stride, map(lambda arg: arg[1], args))\n",
    "    weights.append(tf.Variable(tf.random.truncated_normal([final_image_size * final_image_size * previous_deph, neuron_number], stddev=stddev)))\n",
    "    biases.append(tf.Variable(tf.zeros([neuron_number])))\n",
    "\n",
    "    weights.append(tf.Variable(tf.random.truncated_normal([neuron_number, output_number], stddev=stddev)))\n",
    "    biases.append(tf.Variable(tf.zeros([output_number])))\n",
    "\n",
    "    return weights, biases\n",
    "\n",
    "weights, biases = prepare_weights_biases(shape, num_labels, neurons, padding, stride, [deph, filter], [deph, filter])\n",
    "\n",
    "\n",
    "def calculate_prediction(tf_dataset, weigths, biases, layers):\n",
    "    prev_layer = tf_dataset\n",
    "    for index, layer in enumerate(layers[:-1]):\n",
    "        prev_layer = layer(tf.nn.conv2d(prev_layer, weigths[index], strides=[1, 2, 2, 1], padding='SAME') + biases[index])\n",
    "\n",
    "    shape = prev_layer.get_shape().as_list()\n",
    "    reshape = tf.reshape(prev_layer, [shape[0], shape[1] * shape[2] * shape[3]])\n",
    "    prev_layer = layers[-1](tf.matmul(reshape,  weigths[-2]) + biases[-2])\n",
    "\n",
    "    return tf.matmul(prev_layer, weigths[-1]) + biases[-1]\n",
    "\n",
    "def run_optimization(tf_train_dataset, tf_train_labels, optimizer, weights, biases, layers):\n",
    "    def cost():\n",
    "        return tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=calculate_prediction(tf_train_dataset, weights, biases, layers), labels=tf_train_labels))\n",
    "    optimizer.minimize(cost, weights + biases, tape=tf.GradientTape())\n",
    "\n",
    "def train_model(num_steps, weights, biases, optimizer, layers, optimization_function, calculate_prediction_function, tf_last_activation_function=tf.nn.softmax):\n",
    "    for step, (batch_x, batch_y) in enumerate(dataset.take(num_steps), 1):\n",
    "        optimization_function(batch_x, batch_y, optimizer, weights, biases, layers)\n",
    "        if step % 2000 == 0 or step < 10:\n",
    "            prediction = tf_last_activation_function(calculate_prediction_function(tf_valid_dataset, weights, biases, layers))\n",
    "            print(\"Validation accuracy:\", metrics.accuracy_score(np.argmax(y_valid, 1), np.argmax(prediction, 1)), \"on step:\", step)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.1087 on step: 1\n",
      "Validation accuracy: 0.1115 on step: 2\n",
      "Validation accuracy: 0.1228 on step: 3\n",
      "Validation accuracy: 0.1232 on step: 4\n",
      "Validation accuracy: 0.138 on step: 5\n",
      "Validation accuracy: 0.1375 on step: 6\n",
      "Validation accuracy: 0.145 on step: 7\n",
      "Validation accuracy: 0.1371 on step: 8\n",
      "Validation accuracy: 0.1551 on step: 9\n",
      "Validation accuracy: 0.8564 on step: 2000\n",
      "Validation accuracy: 0.8708 on step: 4000\n",
      "Validation accuracy: 0.878 on step: 6000\n",
      "Validation accuracy: 0.8851 on step: 8000\n",
      "Validation accuracy: 0.8857 on step: 10000\n",
      "Validation accuracy: 0.8918 on step: 12000\n",
      "Validation accuracy: 0.8917 on step: 14000\n",
      "Validation accuracy: 0.8974 on step: 16000\n",
      "Validation accuracy: 0.894 on step: 18000\n",
      "Validation accuracy: 0.8955 on step: 20000\n",
      "Validation accuracy: 0.8994 on step: 22000\n",
      "Validation accuracy: 0.9002 on step: 24000\n",
      "Validation accuracy: 0.8996 on step: 26000\n",
      "Validation accuracy: 0.902 on step: 28000\n",
      "Validation accuracy: 0.9027 on step: 30000\n",
      "Точность на тестовых данных: 0.9512924588763085\n"
     ]
    }
   ],
   "source": [
    "num_steps = 30000\n",
    "train_model(num_steps, weights, biases, optimizer, layers, run_optimization, calculate_prediction)\n",
    "\n",
    "prediction = tf.nn.softmax(calculate_prediction(tf_test_dataset, weights, biases, layers))\n",
    "deep_learning_accuracy = metrics.accuracy_score(np.argmax(y_test, 1), np.argmax(prediction, 1))\n",
    "print(\"Точность на тестовых данных:\", deep_learning_accuracy)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "#2. Замените один из сверточных слоев на слой, реализующий операцию пулинга (Pooling) с функцией максимума или среднего. Как это повлияло на точность классификатора?\n",
    "\n",
    "def calculate_prediction(tf_dataset, weigths, biases, layers):\n",
    "    prev_layer = tf_dataset\n",
    "    for index, layer in enumerate(layers[:-1]):\n",
    "        conv = layer(tf.nn.conv2d(prev_layer, weigths[index], strides=[1, 1, 1, 1], padding='SAME') + biases[index])\n",
    "        prev_layer = tf.nn.max_pool(conv, [1, 2, 2, 1], [1, 2, 2, 1], padding=\"SAME\")\n",
    "\n",
    "    shape = prev_layer.get_shape().as_list()\n",
    "    reshape = tf.reshape(prev_layer, [shape[0], shape[1] * shape[2] * shape[3]])\n",
    "    prev_layer = layers[-1](tf.matmul(reshape,  weigths[-2]) + biases[-2])\n",
    "\n",
    "    return tf.matmul(prev_layer, weigths[-1]) + biases[-1]\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.1545 on step: 1\n",
      "Validation accuracy: 0.1626 on step: 2\n",
      "Validation accuracy: 0.19 on step: 3\n",
      "Validation accuracy: 0.2003 on step: 4\n",
      "Validation accuracy: 0.1834 on step: 5\n",
      "Validation accuracy: 0.1977 on step: 6\n",
      "Validation accuracy: 0.2547 on step: 7\n",
      "Validation accuracy: 0.2868 on step: 8\n",
      "Validation accuracy: 0.239 on step: 9\n",
      "Validation accuracy: 0.8479 on step: 2000\n",
      "Validation accuracy: 0.87 on step: 4000\n",
      "Validation accuracy: 0.8761 on step: 6000\n",
      "Validation accuracy: 0.8849 on step: 8000\n",
      "Validation accuracy: 0.8823 on step: 10000\n",
      "Validation accuracy: 0.8905 on step: 12000\n",
      "Validation accuracy: 0.8904 on step: 14000\n",
      "Validation accuracy: 0.8942 on step: 16000\n",
      "Validation accuracy: 0.8943 on step: 18000\n",
      "Validation accuracy: 0.8962 on step: 20000\n",
      "Validation accuracy: 0.8984 on step: 22000\n",
      "Validation accuracy: 0.8993 on step: 24000\n",
      "Validation accuracy: 0.8979 on step: 26000\n",
      "Validation accuracy: 0.9017 on step: 28000\n",
      "Validation accuracy: 0.8995 on step: 30000\n",
      "Точность на тестовых данных: 0.9521469771416364\n"
     ]
    }
   ],
   "source": [
    "layers = [tf.nn.relu, tf.nn.relu]\n",
    "weights, biases = prepare_weights_biases(shape, num_labels, neurons, padding, stride, [deph, filter])\n",
    "\n",
    "train_model(num_steps, weights, biases, optimizer, layers, run_optimization, calculate_prediction)\n",
    "\n",
    "prediction = tf.nn.softmax(calculate_prediction(tf_test_dataset, weights, biases, layers))\n",
    "deep_learning_accuracy = metrics.accuracy_score(np.argmax(y_test, 1), np.argmax(prediction, 1))\n",
    "print(\"Точность на тестовых данных:\", deep_learning_accuracy)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "#3. Реализуйте классическую архитектуру сверточных сетей LeNet-5\n",
    "\n",
    "def get_final_size(input_size, padding, stride, filters):\n",
    "    output = input_size\n",
    "    for filter in filters:\n",
    "        output = (output + 2 * padding - filter) / stride + 1\n",
    "        output = (output + 2 * padding - 2) / 1 + 1\n",
    "    return int(np.ceil(output))\n",
    "\n",
    "def prepare_weights_biases(input_number, output_number, neuron_number, padding, stride, *args):\n",
    "    weights = []\n",
    "    biases = []\n",
    "    previous_deph = 1\n",
    "    stddev=0.1\n",
    "\n",
    "    for deph, filter in args:\n",
    "        weights.append(tf.Variable(tf.random.truncated_normal([filter, filter, previous_deph, deph], stddev=stddev)))\n",
    "        biases.append(tf.Variable(tf.zeros([deph])))\n",
    "        previous_deph = deph\n",
    "\n",
    "    final_image_size = get_final_size(input_number, padding, stride, map(lambda arg: arg[1], args))\n",
    "    weights.append(tf.Variable(tf.random.truncated_normal([final_image_size * final_image_size * previous_deph, neuron_number[0]], stddev=stddev)))\n",
    "    biases.append(tf.Variable(tf.zeros([neuron_number[0]])))\n",
    "\n",
    "    weights.append(tf.Variable(tf.random.truncated_normal([neuron_number[0], neuron_number[1]], stddev=stddev)))\n",
    "    biases.append(tf.Variable(tf.zeros([neuron_number[1]])))\n",
    "\n",
    "    weights.append(tf.Variable(tf.random.truncated_normal([neuron_number[1], output_number], stddev=stddev)))\n",
    "    biases.append(tf.Variable(tf.zeros([output_number])))\n",
    "\n",
    "    return weights, biases\n",
    "\n",
    "def calculate_prediction_dropout(tf_dataset, weigths, biases, layers):\n",
    "    prev_layer = tf_dataset\n",
    "    keep_prob = 0.1\n",
    "    for index, layer in enumerate(layers[:-2]):\n",
    "        conv = layer(tf.nn.conv2d(prev_layer, weigths[index], strides=[1, 1, 1, 1], padding='VALID') + biases[index])\n",
    "        prev_layer = tf.nn.max_pool(conv, [1, 2, 2, 1], [1, 2, 2, 1], padding=\"VALID\")\n",
    "\n",
    "    shape = prev_layer.get_shape().as_list()\n",
    "    reshape = tf.reshape(prev_layer, [shape[0], shape[1] * shape[2] * shape[3]])\n",
    "    neuron_Layer = layers[-2](tf.matmul(reshape,  weigths[-3]) + biases[-3])\n",
    "    prev_layer = tf.nn.dropout(neuron_Layer, keep_prob)\n",
    "\n",
    "    neuron_Layer = layers[-1](tf.matmul(prev_layer,  weigths[-2]) + biases[-2])\n",
    "    prev_layer = tf.nn.dropout(neuron_Layer, keep_prob)\n",
    "\n",
    "    return tf.matmul(prev_layer, weigths[-1]) + biases[-1]\n",
    "\n",
    "def calculate_prediction(tf_dataset, weigths, biases, layers):\n",
    "    prev_layer = tf_dataset\n",
    "    for index, layer in enumerate(layers[:-2]):\n",
    "        conv = layer(tf.nn.conv2d(prev_layer, weigths[index], strides=[1, 1, 1, 1], padding='VALID') + biases[index])\n",
    "        prev_layer = tf.nn.max_pool(conv, [1, 2, 2, 1], [1, 2, 2, 1], padding=\"VALID\")\n",
    "\n",
    "    shape = prev_layer.get_shape().as_list()\n",
    "    reshape = tf.reshape(prev_layer, [shape[0], shape[1] * shape[2] * shape[3]])\n",
    "    prev_layer = layers[-2](tf.matmul(reshape,  weigths[-3]) + biases[-3])\n",
    "\n",
    "    prev_layer = layers[-1](tf.matmul(prev_layer,  weigths[-2]) + biases[-2])\n",
    "\n",
    "    return tf.matmul(prev_layer, weigths[-1]) + biases[-1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.1297 on step: 1\n",
      "Validation accuracy: 0.1413 on step: 2\n",
      "Validation accuracy: 0.1403 on step: 3\n",
      "Validation accuracy: 0.1304 on step: 4\n",
      "Validation accuracy: 0.1157 on step: 5\n",
      "Validation accuracy: 0.119 on step: 6\n",
      "Validation accuracy: 0.1239 on step: 7\n",
      "Validation accuracy: 0.1471 on step: 8\n",
      "Validation accuracy: 0.1422 on step: 9\n",
      "Validation accuracy: 0.8266 on step: 2000\n",
      "Validation accuracy: 0.8559 on step: 4000\n",
      "Validation accuracy: 0.8682 on step: 6000\n",
      "Validation accuracy: 0.8655 on step: 8000\n",
      "Validation accuracy: 0.8706 on step: 10000\n",
      "Validation accuracy: 0.8744 on step: 12000\n",
      "Validation accuracy: 0.8728 on step: 14000\n",
      "Validation accuracy: 0.8775 on step: 16000\n",
      "Validation accuracy: 0.8791 on step: 18000\n",
      "Validation accuracy: 0.8836 on step: 20000\n",
      "Validation accuracy: 0.8736 on step: 22000\n",
      "Validation accuracy: 0.8827 on step: 24000\n",
      "Validation accuracy: 0.8881 on step: 26000\n",
      "Validation accuracy: 0.8851 on step: 28000\n",
      "Validation accuracy: 0.8818 on step: 30000\n",
      "Точность на тестовых данных: 0.9503311258278145\n"
     ]
    }
   ],
   "source": [
    "padding = 0\n",
    "neuron_number = [100, 60]\n",
    "layers = [tf.nn.relu, tf.nn.relu, tf.nn.relu, tf.nn.relu]\n",
    "learning_rate = tf.keras.optimizers.schedules.ExponentialDecay(start_learning_rate, 5000, 0.96, staircase=True)\n",
    "optimizer = tf.optimizers.SGD(learning_rate)\n",
    "\n",
    "weights, biases = prepare_weights_biases(shape, num_labels, neuron_number, padding, stride, [16, filter], [16, filter])\n",
    "\n",
    "train_model(num_steps, weights, biases, optimizer, layers, run_optimization, calculate_prediction_dropout)\n",
    "\n",
    "prediction = tf.nn.softmax(calculate_prediction(tf_test_dataset, weights, biases, layers))\n",
    "deep_learning_accuracy = metrics.accuracy_score(np.argmax(y_test, 1), np.argmax(prediction, 1))\n",
    "print(\"Точность на тестовых данных:\", deep_learning_accuracy)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Сверточная нейронная сеть: 0.9503311258278145\n",
      "Полносвязная нейронная сеть: 0.9307306131168553\n",
      "Логистическая регрессия: 0.8356\n"
     ]
    }
   ],
   "source": [
    "#4. Сравните максимальные точности моделей, построенных в лабораторных работах 1-3. Как можно объяснить полученные различия?\n",
    "\n",
    "print(\"Сверточная нейронная сеть:\", deep_learning_accuracy)\n",
    "print(\"Полносвязная нейронная сеть:\", 0.9307306131168553)\n",
    "print(\"Логистическая регрессия:\", 0.8356)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}